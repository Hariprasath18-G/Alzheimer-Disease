# -*- coding: utf-8 -*-
"""final project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UauCCHAPaGk8NQaeVbflbUVokUK_J-1O
"""

import pandas as pd
from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from catboost import CatBoostClassifier
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import learning_curve
import numpy as np
from mpl_toolkits.mplot3d import Axes3D

#pip install catboost

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/data.csv")

df['class']

X = df.drop(columns=["class"])
y = df["class"]

object_columns = X.select_dtypes(include=['object']).columns
label_encoders = {}
for col in object_columns:
    label_encoders[col] = LabelEncoder()
    X[col] = label_encoders[col].fit_transform(X[col])

X[col]

X.columns

import plotly.express as px

fig = px.scatter_3d(df, x='air_time1', y='disp_index1', z='gmrt_in_air1', color='class', opacity=0.7)
fig.update_layout(title='3D Scatter Plot of air_time1, disp_index1, and gmrt_in_air1')
fig.show()

feature1 = 'air_time1'
feature2 = 'disp_index1'
feature3 = 'gmrt_in_air1'


class_color_map = {'P': 'blue', 'H': 'red'}


fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')


for cls in df['class'].unique():
    ax.scatter(df[df['class'] == cls][feature1],
               df[df['class'] == cls][feature2],
               df[df['class'] == cls][feature3],
               c=class_color_map[cls],
               label=cls)

ax.set_xlabel(feature1)
ax.set_ylabel(feature2)
ax.set_zlabel(feature3)
ax.set_title('3D Scatter Plot of Selected Features')


ax.legend()

plt.show()

plt.figure(figsize=(8, 6))
plt.hist(df['air_time1'], bins=20, color='skyblue', edgecolor='black')
plt.title('Histogram of air_time1')
plt.xlabel('air_time1')
plt.ylabel('Frequency')
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='class', y='air_time1', data=df)
plt.title('Box Plot of air_time1 Distribution by Class')
plt.xlabel('Class')
plt.ylabel('air_time1')
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(df['air_time1'], df['disp_index1'], color='orange', alpha=0.5)
plt.title('Scatter Plot of air_time1 vs disp_index1')
plt.xlabel('air_time1')
plt.ylabel('disp_index1')
plt.show()

subset_features = df[['air_time1', 'disp_index1', 'gmrt_in_air1', 'max_x_extension1', 'max_y_extension1']]
correlation_matrix = subset_features.corr()


plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Selected Features')
plt.show()

sns.pairplot(df[['air_time1', 'disp_index1', 'gmrt_in_air1', 'class']], hue='class')
plt.title('Pairplot of Selected Features with Class')
plt.show()

plt.figure(figsize=(8, 6))
sns.countplot(x='class', data=df)
plt.title('Count Plot of Class')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

object_columns_list = list(object_columns)

c

y_pred_cat = catboost_model.predict(X_test)

accuracy_cat = accuracy_score(y_test, y_pred_cat)
precision_cat = precision_score(y_test, y_pred_cat, average='weighted')
recall_cat = recall_score(y_test, y_pred_cat, average='weighted')
f1_cat = f1_score(y_test, y_pred_cat, average='weighted')
class_report_cat = classification_report(y_test, y_pred_cat)

print("CatBoost:")
print("Accuracy:", accuracy_cat)
print("Precision:", precision_cat)
print("Recall:", recall_cat)
print("F1-score:", f1_cat)
print("Classification Report:")
print(class_report_cat)

lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, n_estimators=100, random_state=42)
lgb_model.fit(X_train, y_train)

y_pred_lgb = lgb_model.predict(X_test)
accuracy_lgb = accuracy_score(y_test, y_pred_lgb)
precision_lgb = precision_score(y_test, y_pred_lgb, average='weighted')
recall_lgb = recall_score(y_test, y_pred_lgb, average='weighted')
f1_lgb = f1_score(y_test, y_pred_lgb, average='weighted')
class_report_lgb = classification_report(y_test, y_pred_lgb)

y_pred_lgb

print("\nLightGBM:")
print("Accuracy:", accuracy_lgb)
print("Precision:", precision_lgb)
print("Recall:", recall_lgb)
print("F1-score:", f1_lgb)
print("Classification Report:")
print(class_report_lgb)

imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_imputed)
X_test_scaled = scaler.transform(X_test_imputed)

ada_boost = AdaBoostClassifier(n_estimators=50, random_state=42)
ada_boost.fit(X_train_scaled, y_train)

ada_boost = AdaBoostClassifier(n_estimators=50, random_state=42)
ada_boost.fit(X_train_scaled, y_train)
y_pred_ada = ada_boost.predict(X_test_scaled)
accuracy_ada = accuracy_score(y_test, y_pred_ada)
precision_ada = precision_score(y_test, y_pred_ada, average='weighted')
recall_ada = recall_score(y_test, y_pred_ada, average='weighted')
f1_ada = f1_score(y_test, y_pred_ada, average='weighted')
class_report_ada = classification_report(y_test, y_pred_ada)

print("\nAdaBoost:")
print("Accuracy:", accuracy_ada)
print("Precision:", precision_ada)
print("Recall:", recall_ada)
print("F1-score:", f1_ada)
print("Classification Report:")
print(class_report_ada)

models = ['CatBoost', 'LightGBM', 'AdaBoost']
accuracies = [accuracy_cat,accuracy_lgb, accuracy_ada]
plt.figure(figsize=(8, 6))
plt.bar(models, accuracies, color=['blue', 'green', 'orange'],width=0.4)
plt.title('Accuracy of Different Models')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.show()

conf_matrix_cat = confusion_matrix(y_test, y_pred_cat)
conf_matrix_lgb = confusion_matrix(y_test, y_pred_lgb)
conf_matrix_ada = confusion_matrix(y_test, y_pred_ada)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_cat, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - CatBoost')
plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_lgb, annot=True, cmap='Greens', fmt='g')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - LightGBM')
plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_ada, annot=True, cmap='Oranges', fmt='g')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - AdaBoost')
plt.show()

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):
    plt.figure(figsize=(8, 6))
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Training score")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Cross-validation score")

    plt.legend(loc="best")
    return plt


plot_learning_curve(catboost_model, "Learning Curve - CatBoost", X_train, y_train, cv=5)
plt.show()

plot_learning_curve(lgb_model, "Learning Curve - LightGBM", X_train, y_train, cv=5)
plt.show()

plot_learning_curve(ada_boost, "Learning Curve - AdaBoost", X_train, y_train, cv=5)
plt.show()

df.columns